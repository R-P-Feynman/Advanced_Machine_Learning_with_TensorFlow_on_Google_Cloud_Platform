{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(v = tf.logging.INFO)\n",
    "\n",
    "LIST_OF_LABELS = \"daisy,dandelion,roses,sunflowers,tulips\".split(',')\n",
    "HEIGHT = 299\n",
    "WIDTH = 299\n",
    "NUM_CHANNELS = 3\n",
    "NCLASSES = 5\n",
    "\n",
    "def linear_model(img, mode, hparams):\n",
    "    X = tf.reshape(tensor = img, shape = [-1,HEIGHT * WIDTH]) #flatten\n",
    "    ylogits = tf.layers.dense(input = X, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES\n",
    "\n",
    "def dnn_model(img, mode, hparams):\n",
    "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH]) #flatten\n",
    "    h1 = tf.layers.dense(input = X, units = 300, activation = tf.nn.relu)\n",
    "    h2 = tf.layers.dense(input = h1, units = 100, activation = tf.nn.relu)\n",
    "    h3 = tf.layers.dense(input = h2, units = 30, activation = tf.nn.relu)\n",
    "    ylogits = tf.layers.dense(input = h3, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES\n",
    "\n",
    "def dnn_dropout_model(img, mode, hparams):\n",
    "    dprob = hparams.get(\"dprob\", 0.1)\n",
    "\n",
    "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH]) #flatten\n",
    "    h1 = tf.layers.dense(input = X, units = 300, activation = tf.nn.relu)\n",
    "    h2 = tf.layers.dense(input = h1, units = 100, activation = tf.nn.relu)\n",
    "    h3 = tf.layers.dense(input = h2, units = 30, activation = tf.nn.relu)\n",
    "    h3d = tf.layers.dropout(inputs = h3, rate = dprob, training = (mode == tf.estimator.ModeKeys.TRAIN)) #only dropout when training\n",
    "    ylogits = tf.layers.dense(input = h3d, units = NCLASSES, activation = None)\n",
    "    return ylogits, NCLASSES\n",
    "\n",
    "def cnn_model(img, mode, hparams):\n",
    "    ksize1 = hparams.get(\"ksize1\", 5)\n",
    "    ksize2 = hparams.get(\"ksize2\", 5)\n",
    "    nfil1 = hparams.get(\"nfil1\", 10)\n",
    "    nfil2 = hparams.get(\"nfil2\", 20)\n",
    "    dprob = hparams.get(\"dprob\", 0.25)\n",
    "\n",
    "    c1 = tf.layers.conv2d(inputs = img, filters = nfil1,\n",
    "                          kernel_size = ksize1, strides = 1,\n",
    "                          padding = \"same\", activation = tf.nn.relu) # shape = (batch_size, HEIGHT, WIDTH, nfil1)\n",
    "    \n",
    "    p1 = tf.layers.max_pooling2d(inputs = c1, pool_size = 2, strides = 2) # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil1)\n",
    "    \n",
    "    c2 = tf.layers.conv2d(inputs = p1, filters = nfil2,\n",
    "                          kernel_size = ksize2, strides = 1, \n",
    "                          padding = \"same\", activation = tf.nn.relu) # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil2)\n",
    "    \n",
    "    p2 = tf.layers.max_pooling2d(inputs = c2, pool_size = 2, strides = 2) # shape = (batch_size, HEIGHT // 4, WIDTH // 4, nfil2)\n",
    "\n",
    "    outlen = p2.shape[1] * p2.shape[2] * p2.shape[3] # HEIGHT // 4 * WIDTH // 4 * nfil2\n",
    "    p2flat = tf.reshape(tensor = p2, shape = [-1, outlen]) # shape = (batch_size, HEIGHT // 4 * WIDTH // 4 * nfil2)\n",
    "\n",
    "    # Apply batch normalization\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        h3 = tf.layers.dense(inputs = p2flat, units = 300, activation = None)\n",
    "        h3 = tf.layers.batch_normalization(inputs = h3, training = (mode == tf.estimator.ModeKeys.TRAIN)) # only batchnorm when training\n",
    "        h3 = tf.nn.relu(features = h3)\n",
    "    else:  \n",
    "        h3 = tf.layers.dense(inputs = p2flat, units = 300, activation = tf.nn.relu)\n",
    "  \n",
    "    # Apply dropout\n",
    "    h3d = tf.layers.dropout(inputs = h3, rate = dprob, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    ylogits = tf.layers.dense(inputs = h3d, units = NCLASSES, activation = None)\n",
    "  \n",
    "    # Apply batch normalization once more\n",
    "    if hparams[\"batch_norm\"]:\n",
    "        ylogits = tf.layers.batch_normalization(inputs = ylogits, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    return ylogits, NCLASSES\n",
    "\n",
    "def read_and_preprocess_with_augment(image_bytes, label = None):\n",
    "    return read_and_preprocess(image_bytes, label, augment = True)\n",
    "    \n",
    "def read_and_preprocess(image_bytes, label = None, augment = False):\n",
    "    # Decode the image, end up with pixel values that are in the -1, 1 range\n",
    "    image = tf.image.decode_jpeg(contents = image_bytes, channels = NUM_CHANNELS)\n",
    "    image = tf.image.convert_image_dtype(image = image, dtype = tf.float32) # 0-1\n",
    "    image = tf.expand_dims(input = image, axis = 0) # resize_bilinear needs batches\n",
    "    \n",
    "    if augment:\n",
    "        image = tf.image.resize_bilinear(images = image, size = [HEIGHT + 10, WIDTH + 10], align_corners = False)\n",
    "        image = tf.squeeze(input = image, axis = 0) # remove batch dimension\n",
    "        image = tf.random_crop(value = image, size = [HEIGHT, WIDTH, NUM_CHANNELS])\n",
    "        image = tf.image.random_flip_left_right(image = image)\n",
    "        image = tf.image.random_brightness(image = image, max_delta = 63.0 / 255.0)\n",
    "        image = tf.image.random_contrast(image = image, lower = 0.2, upper = 1.8)\n",
    "    else:\n",
    "        image = tf.image.resize_bilinear(images = image, size = [HEIGHT, WIDTH], align_corners = False)\n",
    "        image = tf.squeeze(input = image, axis = 0) # remove batch dimension\n",
    "        \n",
    "    # Pixel values are in range [0,1], convert to [-1,1]\n",
    "    image = tf.subtract(x = image, y = 0.5)\n",
    "    image = tf.multiply(x = image, y = 2.0)\n",
    "    return {\"image\": image}, label\n",
    "\n",
    "def serving_input_fn():\n",
    "    # Note: only handles one image at a time \n",
    "    feature_placeholders = {\"image_bytes\": tf.placeholder(dtype = tf.string, shape = [])}\n",
    "    image, _ = read_and_preprocess(tf.squeeze(input = feature_placeholders[\"image_bytes\"]))\n",
    "    image[\"image\"] = tf.expand_dims(image[\"image\"], axis = 0)\n",
    "    return tf.estimator.export.ServingInputReceiver(features = image, receiver_tensors = feature_placeholders)\n",
    "\n",
    "def make_input_fn(csv_of_filenames, batch_size, mode, augment = False):\n",
    "    def _input_fn():\n",
    "        def decode_csv(csv_row):\n",
    "            filename, label = tf.decode_csv(records = csv_row, record_defaults = [[\"\"],[\"\"]])\n",
    "            image_bytes = tf.read_file(filename = filename)\n",
    "            return image_bytes, label\n",
    "        \n",
    "        # Create tf.data.dataset from filename\n",
    "        dataset = tf.data.TextLineDataset(filenames = csv_of_filenames).map(map_func = decode_csv)     \n",
    "        \n",
    "        if augment: \n",
    "            dataset = dataset.map(map_func = read_and_preprocess_with_augment)\n",
    "        else:\n",
    "            dataset = dataset.map(map_func = read_and_preprocess)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    " \n",
    "        dataset = dataset.repeat(count = num_epochs).batch(batch_size = batch_size)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    return _input_fn\n",
    "    \n",
    "def image_classifier(features, labels, mode, params):\n",
    "    model_functions = {\n",
    "        \"linear\": linear_model,\n",
    "        \"dnn\": dnn_model,\n",
    "        \"dnn_dropout\": dnn_dropout_model,\n",
    "        \"cnn\": cnn_model}\n",
    "    model_function = model_functions[params[\"model\"]] \n",
    "    ylogits, nclasses = model_function(features[\"image\"], mode, params)\n",
    "\n",
    "    probabilities = tf.nn.softmax(logits = ylogits)\n",
    "    class_int = tf.cast(x = tf.argmax(input = ylogits, axis = 1), dtype = tf.uint8)\n",
    "    class_str = tf.gather(params = LIST_OF_LABELS, indices = tf.cast(x = class_int, dtype = tf.int32))\n",
    "  \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        # Convert string label to int\n",
    "        labels_table = tf.contrib.lookup.index_table_from_tensor(mapping = tf.constant(value = LIST_OF_LABELS, dtype = tf.string))\n",
    "        labels = labels_table.lookup(keys = labels)\n",
    "\n",
    "        loss = tf.reduce_mean(input_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits = ylogits, labels = tf.one_hot(indices = labels, depth = NCLASSES)))\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # This is needed for batch normalization, but has no effect otherwise\n",
    "            update_ops = tf.get_collection(key = tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(control_inputs = update_ops):\n",
    "                train_op = tf.contrib.layers.optimize_loss(\n",
    "                    loss = loss, \n",
    "                    global_step = tf.train.get_global_step(),\n",
    "                    learning_rate = params[\"learning_rate\"],\n",
    "                    optimizer = \"Adam\")\n",
    "            eval_metric_ops = None\n",
    "        else:\n",
    "            train_op = None\n",
    "            eval_metric_ops =  {\"accuracy\": tf.metrics.accuracy(labels = labels, predictions = class_int)}\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    " \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = {\"probabilities\": probabilities, \n",
    "                       \"classid\": class_int, \n",
    "                       \"class\": class_str},\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = {\"classes\": tf.estimator.export.PredictOutput(\n",
    "            {\"probabilities\": probabilities, \n",
    "             \"classid\": class_int, \n",
    "             \"class\": class_str})}\n",
    "    )\n",
    "\n",
    "def train_and_evaluate(output_dir, hparams):\n",
    "    tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "    \n",
    "    EVAL_INTERVAL = 300 # every 5 minutes\n",
    "    \n",
    "    # Instantiate base estimator class for custom model function\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn = image_classifier,\n",
    "        params = hparams,\n",
    "        config = tf.estimator.RunConfig(\n",
    "            save_checkpoints_secs = EVAL_INTERVAL),\n",
    "            model_dir = output_dir)\n",
    "    \n",
    "    # Set estimator's train_spec to use train_input_fn and train for so many steps\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = make_input_fn(\n",
    "            hparams['train_data_path'],\n",
    "            hparams['batch_size'],\n",
    "            mode = tf.estimator.ModeKeys.TRAIN,\n",
    "            augment = hparams['augment']),\n",
    "        max_steps = hparams[\"train_steps\"])\n",
    "\n",
    "    # Create exporter that uses serving_input_fn to create saved_model for serving\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name = \"exporter\", \n",
    "        serving_input_receiver_fn = serving_input_fn)\n",
    "\n",
    "    # Set estimator's eval_spec to use eval_input_fn and export saved_model\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = make_input_fn(\n",
    "            hparams['eval_data_path'],\n",
    "            hparams['batch_size'],\n",
    "            mode = tf.estimator.ModeKeys.EVAL),\n",
    "        steps = None,\n",
    "        exporters = exporter,\n",
    "        start_delay_secs = EVAL_INTERVAL,\n",
    "        throttle_secs = EVAL_INTERVAL)\n",
    "\n",
    "    # Run train_and_evaluate loop\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator = estimator, \n",
    "        train_spec = train_spec, \n",
    "        eval_spec = eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
